
 
 <h2>Introduction</h2>

In order for computer systems to interpret the subject of a text in a similar way humans do, they use **natural language processing** (NLP), an area within AI that deals with understanding written or spoken language, and responding in kind. _Text analysis_ describes NLP processes that extract information from unstructured text.


# Understand Text Analytics
## Tokenization

The first step in analyzing a corpus is to break it down into _tokens_. For the sake of simplicity, you can think of each distinct word in the training text as a token, though in reality, tokens can be generated for partial words, or combinations of words and punctuation.

For example, consider this phrase from a famous US presidential speech: "_we choose to go to the moon_". The phrase can be broken down into the following tokens, with numeric identifiers:

1. we
2. choose
3. to
4. go
5. the
6. moon

Notice that "to" (token number 3) is used twice in the corpus. The phrase "_we choose to go to the moon_" can be represented by the tokens [_1,2,3,4,3,5,6_].



>[!warning]
We've used a simple example in which tokens are identified for each distinct word in the text. However, consider the following concepts that may apply to tokenization depending on the specific kind of NLP problem you're trying to solve:
>- **Text normalization**: Before generating tokens, you may choose to _normalize_ the text by removing punctuation and changing all words to lower case. For analysis that relies purely on word frequency, this approach improves overall performance. However, some semantic meaning may be lost - for example, consider the sentence "_Mr Banks has worked in many banks._". You may want your analysis to differentiate between the person _Mr Banks_ and the _banks_ in which he has worked. You may also want to consider "_banks._" as a separate token to "_banks_" because the inclusion of a period provides the information that the word comes at the end of a sentence
>- **Stop word removal**. Stop words are words that should be excluded from the analysis. For example, "_the_", "_a_", or "_it_" make text easier for people to read but add little semantic meaning. By excluding these words, a text analysis solution may be better able to identify the important words.
>- **n-grams** are multi-term phrases such as "I have" or "he walked". A single word phrase is a _unigram_, a two-word phrase is a _bi-gram_, a three-word phrase is a _tri-gram_, and so on. By considering words as groups, a machine learning model can make better sense of the text.
>- **Stemming** is a technique in which algorithms are applied to consolidate words before counting them, so that words with the same root, like "power", "powered", and "powerful", are interpreted as being the same token.

## Frequency analysis

After tokenizing the words, you can perform some analysis to count the number of occurrences of each token. The most commonly used words (other than _stop words_ such as "_a_", "_the_", and so on) can often provide a clue as to the main subject of a text corpus. For example, the most common words in the entire text of the "go to the moon" speech we considered previously include "_new_", "_go_", "_space_", and "_moon_". If we were to tokenize the text as bi-grams (word pairs), the most common bi-gram in the speech is "_the moon_". From this information, we can easily surmise that the text is primarily concerned with space travel and going to the moon.



## Machine learning for text classification

Another useful text analysis technique is to use a classification algorithm, such as _logistic regression_, to train a machine learning model that classifies text based on a known set of categorizations. A common application of this technique is to train a model that classifies text as _positive_ or _negative_ in order to perform _sentiment analysis_ or _opinion mining_.

For example, consider the following restaurant reviews, which are already labeled as **0** (_negative_) or **1** (_positive_):

- _The food and service were both great_: 1
- _A really terrible experience_: 0
- _Mmm! tasty food and a fun vibe_: 1
- _Slow service and substandard food_: 0

With enough labeled reviews, you can train a classification model using the tokenized text as _features_ and the sentiment (0 or 1) a _label_. The model will encapsulate a relationship between tokens and sentiment - for example, reviews with tokens for words like _"great_", "_tasty_", or "_fun_" are more likely to return a sentiment of **1** (_positive_), while reviews with words like "_terrible_", "_slow_", and "_substandard_" are more likely to return **0** (_negative_).


## Semantic language models

As the state of the art for NLP has advanced, the ability to train models that encapsulate the semantic relationship between tokens has led to the emergence of powerful language models. At the heart of these models is the encoding of language tokens as vectors (multi-valued arrays of numbers) known as _embeddings_.

It can be useful to think of the elements in a token embedding vector as coordinates in multidimensional space, so that each token occupies a specific "location." The closer tokens are to one another along a particular dimension, the more semantically related they are. In other words, related words are grouped closer together. As a simple example, suppose the embeddings for our tokens consist of vectors with three elements, for example:

- 4 ("dog"): [10.3.2]
- 5 ("bark"): [10,2,2]
- 8 ("cat"): [10,3,1]
- 9 ("meow"): [10,2,1]
- 10 ("skateboard"): [3,3,1]

We can plot the location of tokens based on these vectors in three-dimensional space, like this:
![[Pasted image 20240414221958.png]]

The locations of the tokens in the embeddings space include some information about how closely the tokens are related to one another. For example, the token for "dog" is close to "cat" and also to "bark." The tokens for "cat" and "bark" are close to "meow." The token for "skateboard" is further away from the other tokens.

The language models we use in industry are based on these principles but have greater complexity. For example, the vectors used generally have many more dimensions. There are also multiple ways you can calculate appropriate embeddings for a given set of tokens. Different methods result in different predictions from natural language processing models.


<h3> A generalized view of modern NLP solution </h3>
![[Pasted image 20240414222101.png]]

Common NLP tasks supported by language models include:

- Text analysis, such as extracting key terms or identifying named entities in text.
- Sentiment analysis and opinion mining to categorize text as _positive_ or _negative_.
- Machine translation, in which text is automatically translated from one language to another.
- Summarization, in which the main points of a large body of text are summarized.
- Conversational AI solutions such as _bots_ or _digital assistants_ in which the language model can interpret natural language input and return an appropriate response.


<h3> Azure AI text analysis </h3>
**Azure AI Language** is a part of the Azure AI services offerings that can perform advanced natural language processing over unstructured text. Azure AI Language's text analysis features include:

- **Named entity recognition** identifies people, places, events, and more. This feature can also be customized to extract custom categories.
- **Entity linking** identifies known entities together with a link to Wikipedia.
- **Personal identifying information (PII) detection** identifies personally sensitive information, including personal health information (PHI).
- **Language detection** identifies the language of the text and returns a language code such as "en" for English.
- **Sentiment analysis and opinion mining** identifies whether text is positive or negative.
- **Summarization** summarizes text by identifying the most important information.
- **Key phrase extraction** lists the main concepts from unstructured text.

## Language detection

Use the language detection capability of Azure AI Language to identify the language in which text is written. You can submit multiple documents at a time for analysis. For each document submitted the service will detect:

## Sentiment analysis and opinion mining

The text analytics capabilities in Azure AI Language can evaluate text and return sentiment scores and labels for each sentence. This capability is useful for detecting positive and negative sentiment in social media, customer reviews, discussion forums and more.


## Key phrase extraction

Key phrase extraction identifies the main points from text. Consider the restaurant scenario discussed previously. If you have a large number of surveys, it can take a long time to read through the reviews. Instead, you can use the key phrase extraction capabilities of the Language service to summarize the main points.



# Knowledge check

1.

You want to use Azure AI Language to determine the key talking points in a text document. Which feature of the service should you use?

Sentiment analysis

Key phrase extraction

Correct. Key phrases can be used to identify the main talking points in a text document.

Entity detection

2.

You use Azure AI Language to perform sentiment analysis on a sentence. The confidence scores .04 positive, .36 neutral, and .60 negative are returned. What do these confidence scores indicate about the sentence sentiment?

The document is positive.

The document is neutral.

The document is negative.

Correct. The sentiment is most likely the type with the highest confidence score, in this case .6 negative.

3.

When might you see **NaN** returned for a score in language detection?

When the score calculated by the service is outside the range of 0 to 1

When the predominant language in the text is mixed with other languages

When the language is ambiguous

Correct. The service will return **NaN** when it can't determine the language in the provided text.


# Summary

Azure AI Language provides advanced natural language processing over raw text, and includes four main functions: sentiment analysis, key phrase extraction, language detection, and named entity recognition.